# Context retaining chatbot

This project implements a chatbot backend using LangChain with support for contextual memory, enabling more human-like and continuous conversations. It demonstrates how to:

- Integrate language models with memory for chat history retention
- Build a flexible, extendable backend for contextual applications
- Support multi-turn conversations with user-specific session memory

Ideal for developers building AI assistants, customer support agents, or any use case requiring stateful interaction with LLMs.

### Prerequisite installations & steps

- VS Code
- Python
- AWS CLI
- AWS Toolkit and AWS Boto3 VSCode extensions
- AWS configure
- Anaconda navigator
- Open VS Code from Anaconda Navigator
- Install boto 3
- Install Langchain
- Install Langchain-AWS Module
- Install Streamlit
- Install Transformers
- Install PyYAML

#### Command to run Chatbot UI
```
streamlit run mychatbot_frontend.py
```
