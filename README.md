# Context retaining chatbot

This project implements a chatbot backend using LangChain with support for contextual memory, enabling more human-like and continuous conversations. It demonstrates how to:

- Integrate language models with memory for chat history retention
- Build a flexible, extendable backend for contextual applications
- Support multi-turn conversations with user-specific session memory

Ideal for developers building AI assistants, customer support agents, or any use case requiring stateful interaction with LLMs.

### Prerequisite installations & steps

- VS Code
- Python
- AWS CLI
- AWS Toolkit and AWS Boto3 VSCode extensions
- AWS configure
- Anaconda navigator
- Open VS Code from Anaconda Navigator
- Install boto 3
- Install Langchain
- Install Langchain-AWS Module
- Install Streamlit
- Install Transformers
- Install PyYAML

#### Command to run Chatbot UI
```
streamlit run mychatbot_frontend.py
```

#### Architecture


<img width="1305" alt="Screenshot 2025-05-25 at 9 25 09â€¯PM" src="https://github.com/user-attachments/assets/ce9307f6-5f07-482a-9c53-3313c278259b" />

#### Demo - [here](https://www.linkedin.com/posts/pavan-kumar-uppuluri-758325359_ai-chatbot-langchain-activity-7332450766160367616-9B_-?utm_source=share&utm_medium=member_desktop&rcm=ACoAAFk2-_QBAbcGmqoTSyPXyBnf9KxcVYMQ4Z0)
